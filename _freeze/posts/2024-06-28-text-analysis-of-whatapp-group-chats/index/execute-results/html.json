{
  "hash": "4a5a2e8079990bfaeb75bae68b46b76f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Text analysis of whatapp group chats\nauthor: Shaun Nielsen\ndate: '2024-06-28'\ncategories: ['text-analysis']\ntags: ['visualisation', 'text']\n---\n\n\nI recently began to read the [\"Text Mining with R\" book](https://www.tidytextmining.com/) from by Julia Silge and David Robinson. I thought I would apply this knowledge to my Whatapp group chats\n\n<!--more-->\n\n## Exporting the data\n\nWhatsapp allows you to export chats to a text file. For long running, or message intensive chats this does not always work - Whatapp sucks sometimes. I was fortunate enough to be able to export my group chat that begun in Janurary 2023. Furthermore, you can export with or without media. Since I was doing a text analysis, I chose to export without media.\n\nWithin whatapp on my phone, I went to the group chat \\> chat options (3 vertical dots) \\> more \\> Export chat \\> Without media, and exported the chat to my my googledrive. I then copied the file to my project directory.\n\n```         \nepl-chat.txt\n```\n\n## The data\n\nThe data is a text file with each line a message from the chat. We use `readLines()` to import it into R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_raw <- readLines(\"epl-chat.txt\")\n```\n:::\n\n::: {.cell}\n\n:::\n\n\nThere were 27308 messages in this file\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlength(chat_raw)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 27308\n```\n\n\n:::\n:::\n\n\nThe general structure of the messages are\n\n-   timestamp\n-   name\n-   message text\n\nNote: there are some messages that do not follow this structure and they are messages involved with the chat setup e.g. \"Person added you\" or \"Person left the chat\", or when there are multi-line messages, or for some other reason.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(chat_raw)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"5/1/23, 3:54‚ÄØam - Messages and calls are end-to-end encrypted. No one outside of this chat, not even WhatsApp, can read or listen to them. Tap to learn more.\"\n[2] \"5/1/23, 3:54‚ÄØam - Gerrard created group \\\"Real EPL Chat\\\"\"                                                                                                    \n[3] \"5/1/23, 3:54‚ÄØam - Gerrard added you\"                                                                                                                          \n[4] \"5/1/23, 3:54‚ÄØam - Gerrard changed this group's icon\"                                                                                                          \n[5] \"5/1/23, 3:55‚ÄØam - Gerrard: Putting the other chat on Mute and seeing how it takes for the English to notice\"                                                  \n[6] \"5/1/23, 3:56‚ÄØam - Gerrard: Think we should have a catch over a game sometime, it's been a long while for some of us\"                                          \n```\n\n\n:::\n:::\n\n\n## Data wrangling\n\n### Packages\n\nWe use tidyverse packages `dplyr`, `tidyr` and `ggplot2` as well as `tidytext`, `emoji` and `wordcloud` packages.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tidytext)\nlibrary(emoji)\nlibrary(ggplot2)\nlibrary(wordcloud)\n```\n:::\n\n\n### Fix multi-line messages\n\nWhen there is a newline character in a message i.e. a message with multple lines, it will create a new line in the exported chat. We want all the text from a message to be on one line, and in-line with the timestamp and name.\n\nFor example\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Output lines 2:4 are from the same message\nchat_raw[123:127]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"30/1/23, 11:02‚ÄØam - Gerrard: Hungover and typical emo professional sportsmen\"                                         \n[2] \"30/1/23, 11:26‚ÄØam - Jono: https://twitter.com/skysportsnews/status/1620004706159296519?s=48&t=Dltf9xxkoAIEO9BGNlNHWw \"\n[3] \"\"                                                                                                                     \n[4] \"The replies lol\"                                                                                                      \n[5] \"31/1/23, 11:29‚ÄØam - Gerrard: <Media omitted>\"                                                                         \n```\n\n\n:::\n:::\n\n\nWe can identify where these occur by checking if the line begins with a date\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Return row indices of lines not starting with a date\nstarts_with_1_or_2_digits <- '^[[:digit:]]{1,2}/'\n\nnot <- function(x){ !x }\n\nmultiline_msgs <-\n  grepl(pattern = starts_with_1_or_2_digits, x = chat_raw) |>\n    not() |>\n    which()\n\n# Note 125, 126 and 825, 826 are each part of multi-line messages\nhead(multiline_msgs)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 125 126 307 825 826 828\n```\n\n\n:::\n:::\n\n\nThe root message of these is then the index - 1 (the previous message)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 124 with 125, 126\nchat_raw[124:126]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"30/1/23, 11:26‚ÄØam - Jono: https://twitter.com/skysportsnews/status/1620004706159296519?s=48&t=Dltf9xxkoAIEO9BGNlNHWw \"\n[2] \"\"                                                                                                                     \n[3] \"The replies lol\"                                                                                                      \n```\n\n\n:::\n\n```{.r .cell-code}\n# 824 with 825, 826\nchat_raw[824:826]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"13/7/23, 12:35‚ÄØpm - Jono: https://twitter.com/utdfaithfuls/status/1679411517538594816?s=48\"\n[2] \"\"                                                                                          \n[3] \"Pretty fucking crazy\"                                                                      \n```\n\n\n:::\n:::\n\n\n#### Joining multi-line messages\n\nThe algorithm to fix these would be to\n\n-   start at the last index and paste that text with the index - 1 text (the previous message)\n-   repeat for all multi-line indices\n-   finally, remove multi-line indices\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_raw_single <- chat_raw\n\nfor(curr_msg_ind in rev(multiline_msgs)){\n  \n  # Paste with previous message\n  prev_msg_ind = curr_msg_ind - 1\n  \n  chat_raw_single[prev_msg_ind] <-\n    paste(chat_raw_single[prev_msg_ind],\n          chat_raw_single[curr_msg_ind])\n  \n  # Finally remove mutli-line messages\n  if (curr_msg_ind == multiline_msgs[1]) {\n    chat_raw_single <-\n      chat_raw_single[-multiline_msgs]\n    \n  }\n  \n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_raw_single[124]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"30/1/23, 11:26‚ÄØam - Jono: https://twitter.com/skysportsnews/status/1620004706159296519?s=48&t=Dltf9xxkoAIEO9BGNlNHWw   The replies lol\"\n```\n\n\n:::\n\n```{.r .cell-code}\nchat_raw_single[821] # index lower since we removed lines\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"13/7/23, 12:35‚ÄØpm - Jono: https://twitter.com/utdfaithfuls/status/1679411517538594816?s=48  Pretty fucking crazy\"\n```\n\n\n:::\n:::\n\n\n### Parse text data\n\nThe first goal is to split the messages into a 3-column data.frame by:\n\n-   timestamp\n-   name\n-   message text\n\nThe timestamp is separated from the name and text components with `-`, and the name is separated from the text with a `:`.\n\n#### Split time from name-text\n\nNote: if `-` is found anywhere else in the message line, then it will create additional splits.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_split_raw <-\n  chat_raw_single |>\n  strsplit(split = ' - ')\n```\n:::\n\n\nThis should return a large list of lists, each with 2 elements - the timestamp and the name-text.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_split_raw[10:12]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n[1] \"5/1/23, 3:58‚ÄØam\"   \"Gerrard: Added JD\"\n\n[[2]]\n[1] \"5/1/23, 4:00‚ÄØam\"          \"Gerrard: <Media omitted>\"\n\n[[3]]\n[1] \"5/1/23, 4:01‚ÄØam\"          \"Gerrard: <Media omitted>\"\n```\n\n\n:::\n:::\n\n\nFor quality control, we can count the number of elements in each split to identify where there are **not** 2 elements - messages that do not follow the timestamp-name-text convention, or where there are additional `-` in the message text, or something else we do not know about\n\nBelow shows there are messages with 2 to 6 split elements\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsplit_counts <- \n  chat_split_raw |>\n  sapply(length)\n\nsplit_counts |>\n  table()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nsplit_counts\n    2     3     4     5     6 \n25842   136     6     2     1 \n```\n\n\n:::\n:::\n\n\nIt looks like most, if not all, of the cases with 3 to 6 elements are because of multiple `-` in the message.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_raw_single[ split_counts == 3 ][1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"20/1/23, 4:01‚ÄØam - Jono: Banter days are dead - Wilson is harmless lol\"                                                                                                                                           \n[2] \"16/2/23, 4:07‚ÄØam - Jono: Physically - watch the goal and you'll see what i mean\"                                                                                                                                  \n[3] \"18/7/23, 12:07‚ÄØpm - Gerrard: When it's against Maddison and Tottenham, Pero says Always Was Always Will Be - Change The Date\"                                                                                     \n[4] \"21/7/23, 6:14‚ÄØam - Jono: 2 goals in 3 matches - bitches\"                                                                                                                                                          \n[5] \"27/7/23, 12:44‚ÄØpm - Gerrard: Also got: Islamic Prophets Family Tree, Alien 3 - WTF Happened To This Movie?, Welcome To Stealth Camping, TalkSport, Bronze Art Warfare, 8 Out Of 10 Cats Does Countdown Highlights\"\n```\n\n\n:::\n\n```{.r .cell-code}\nchat_raw_single[ split_counts >= 4 ]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"10/11/23, 5:09‚ÄØam - Gerrard: https://youtu.be/heTMlxdiYH8?si=RI9O4FUtH__vOq1h @61452662705  All these explayers pundits missing the point about refs, saying they've never played, get explayers in to be refs, etc. The refs are mostly enforcing the letter of the law - not the \\\"he didn't mean it\\\", \\\"no intent\\\" - it's the law changes that are fucking up the games. Change the law.\"\n[2] \"15/11/23, 5:07‚ÄØam - Dave: We‚Äôve won more trophies than you both combined in the last 30 years.   Arsenal - 24  Liverpool - 19  Newcastle - 0   Currently 1 point off top of the league and top of our champions league group. Exactly where we want to be. COYG üî¥ ‚ö™Ô∏è ‚ù§Ô∏è\"                                                                                                                       \n[3] \"27/12/23, 11:59‚ÄØpm - Dave: 8th - 5th - 2nd\"                                                                                                                                                                                                                                                                                                                                                   \n[4] \"15/1/24, 10:00‚ÄØpm - Dave: Arsenals starting 11 - 370m Liverpools starting 11 - 532m   162m more yet Klip is the hard done by genius let down by FSG\"                                                                                                                                                                                                                                          \n[5] \"20/1/24, 8:48‚ÄØam - Dave: - Newtle essentially have a full strength starting 11 but blame injuries  - There‚Äôs a conspiracy theory against Newtle to not let them back in top 6 because it‚Äôs bad for business    - A debate is being had whether Liverpool had any meaningful injuries in 2021  - Rory Jennings is a massive clueless cunt\"                                                     \n[6] \"8/4/24, 2:00‚ÄØam - Dave: W   D   L  1 - 5 - 2  Title contenders @61452662705\"                                                                                                                                                                                                                                                                                                                  \n[7] \"24/4/24, 10:01‚ÄØam - James: Probably win the same amount of titles if you fold versus employing rent - a - ten hag <This message was edited>\"                                                                                                                                                                                                                                                  \n[8] \"25/4/24, 12:31‚ÄØam - Liam: Liverpool quad dream finished by: fa cup - united  Europa - Atalanta  PL - Everton\"                                                                                                                                                                                                                                                                                 \n[9] \"28/5/24, 3:02‚ÄØpm - Dave: Rice - 100m  7 goals  8 assists   Mac and slob combined - 125m 8 goals  7 assists  Klopps flopps, no wonder he abandoned youse\"                                                                                                                                                                                                                                      \n```\n\n\n:::\n:::\n\n\nWe can fix this by simply pasting the 2nd to nth elements together. We will need to do this again later, so I created a function for doing this\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Paste the 2nd to nth elements together\npaste_2_nth <- function(x, collapse){\n    c(x[1],\n      paste(x[2:length(x)], collapse = collapse))\n}\n\n# Example\npaste_2_nth(c('time', 'text1', 'text2'), collapse = ' - ')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"time\"          \"text1 - text2\"\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_split_time <-\n  chat_split_raw |>\n  lapply(FUN = paste_2_nth, collapse = ' - ')\n\nchat_split_time |>\n  sapply(length) |>\n  table()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n    2 \n25987 \n```\n\n\n:::\n:::\n\n\n#### Split name from text\n\nWe can split the name-text using a similar approach to above but using `:`. Again, if there are multiple `:` in a message, we will split the text multiple times, and need to paste the 2nd to nth back together (using the function we created above)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_split_final <-\n  chat_split_time |>\n  lapply(FUN = function(msg){\n    \n    timestamp <- msg[1]\n    name_text <- msg[2]\n    \n    # Split name and text\n    name_text_2 <-\n      name_text |>\n      strsplit(split = ': ') |>\n      lapply(FUN = paste_2_nth, collapse = ': ') |>\n      unlist() |>\n      setNames(c('name', 'text'))\n    \n    # Return  named 3 element vector\n    c(time = timestamp, name_text_2)\n    \n  })\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_split_final[10:12]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n             time              name              text \n\"5/1/23, 3:58‚ÄØam\"         \"Gerrard\"        \"Added JD\" \n\n[[2]]\n             time              name              text \n\"5/1/23, 4:00‚ÄØam\"         \"Gerrard\" \"<Media omitted>\" \n\n[[3]]\n             time              name              text \n\"5/1/23, 4:01‚ÄØam\"         \"Gerrard\" \"<Media omitted>\" \n```\n\n\n:::\n\n```{.r .cell-code}\nchat_split_final |>\n  sapply(length) |>\n  table()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n    3 \n25987 \n```\n\n\n:::\n:::\n\n\n#### Create data.frame\n\nWe will work with the data in a data.frame from here on.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_df <-\n  chat_split_final |>\n  dplyr::bind_rows()\n\nchat_df[10:15,]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 √ó 3\n  time            name    text                                                  \n  <chr>           <chr>   <chr>                                                 \n1 5/1/23, 3:58‚ÄØam Gerrard Added JD                                              \n2 5/1/23, 4:00‚ÄØam Gerrard <Media omitted>                                       \n3 5/1/23, 4:01‚ÄØam Gerrard <Media omitted>                                       \n4 5/1/23, 4:02‚ÄØam Gerrard <Media omitted>                                       \n5 5/1/23, 4:03‚ÄØam Gerrard <Media omitted>                                       \n6 5/1/23, 4:03‚ÄØam Gerrard Put some thoughts together on these, or just find a n‚Ä¶\n```\n\n\n:::\n:::\n\n\n### Cleaning names\n\nSome of the names of messages are a result of changes to the group itself, such as changing the group name, people coming and going, etc. We need to remove these.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_df |>\n  dplyr::count(name) |> \n  print(n = Inf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 43 √ó 2\n   name                                                                        n\n   <chr>                                                                   <int>\n 1 \"Anthony\"                                                                  41\n 2 \"Chandra\"                                                                  21\n 3 \"Chris\"                                                                   300\n 4 \"Dave\"                                                                   4223\n 5 \"Gerrard\"                                                                7962\n 6 \"Gerrard added Dave and Liam\"                                               1\n 7 \"Gerrard added JD\"                                                          1\n 8 \"Gerrard added James\"                                                       1\n 9 \"Gerrard added you\"                                                         1\n10 \"Gerrard changed the group name from \\\"Contender Friends\\\" to \\\"Good S‚Ä¶     1\n11 \"Gerrard changed the group name from \\\"Good Stats Friends\\\" to \\\"Teams‚Ä¶     1\n12 \"Gerrard changed the group name from \\\"Negative energy only Group Chat‚Ä¶     1\n13 \"Gerrard changed the group name from \\\"Real EPL Chat\\\" to \\\"Real Liver‚Ä¶     1\n14 \"Gerrard changed the group name from \\\"Real Liverpool Pats Chat\\\" to \\‚Ä¶     1\n15 \"Gerrard changed the group name from \\\"Title Challengers Group Chat + ‚Ä¶     1\n16 \"Gerrard changed this group's icon\"                                         7\n17 \"Gerrard created group \\\"Real EPL Chat\\\"\"                                   1\n18 \"Gerrard turned off disappearing messages.\"                                 1\n19 \"JD\"                                                                       27\n20 \"James\"                                                                  7286\n21 \"James turned off disappearing messages.\"                                   2\n22 \"Jono\"                                                                   3694\n23 \"Jono changed the group name from \\\"Title Challengers & Arsenal Fans &‚Ä¶     1\n24 \"Jono changed the group name from \\\"Title Challengers & Arsenal Fans G‚Ä¶     1\n25 \"Jono changed the group name from \\\"Weekly Refereeing Group Chat\\\" to ‚Ä¶     1\n26 \"Jono changed this group's icon\"                                            3\n27 \"Liam\"                                                                    906\n28 \"Louie\"                                                                   193\n29 \"Messages and calls are end-to-end encrypted. No one outside of this c‚Ä¶     1\n30 \"Pero\"                                                                   1033\n31 \"Shaun\"                                                                   192\n32 \"Wilson\"                                                                   63\n33 \"You changed this group's icon\"                                             2\n34 \"You updated the message timer. New messages will disappear from this ‚Ä¶     3\n35 \"You're now an admin\"                                                       1\n36 \"~‚ÄØDave added James\"                                                        1\n37 \"~‚ÄØDave changed this group's icon\"                                          4\n38 \"~‚ÄØDave left\"                                                               1\n39 \"~‚ÄØJames changed the group name from \\\"Auf Wiedersehen Klapp\\\" to \\\"Co‚Ä¶     1\n40 \"~‚ÄØJames changed the group name from \\\"Title Challengers & Arsenal Fan‚Ä¶     1\n41 \"~‚ÄØJames changed this group's icon\"                                         2\n42 \"~‚ÄØJames left\"                                                              1\n43 \"~‚ÄØLiam Keepence added Dave\"                                                1\n```\n\n\n:::\n:::\n\n\nWe can match those \"names\" we do not want\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_df_clean <-\n  chat_df |>\n  dplyr::filter(!grepl(' added |left$| changed | created |^Messages|an admin$|messages.$| message timer', name))\n```\n:::\n\n\nNow we have only true messages from people in the group\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_df_clean |>\n  dplyr::count(name) |> \n  print(n = Inf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 13 √ó 2\n   name        n\n   <chr>   <int>\n 1 Anthony    41\n 2 Chandra    21\n 3 Chris     300\n 4 Dave     4223\n 5 Gerrard  7962\n 6 JD         27\n 7 James    7286\n 8 Jono     3694\n 9 Liam      906\n10 Louie     193\n11 Pero     1033\n12 Shaun     192\n13 Wilson     63\n```\n\n\n:::\n:::\n\n\n### Cleaning messages\n\nWhen we choose to exlcude media in the Whatapp export, it still exports that a message was created but with the text `\"<Media omitted>\"`. We want to remove such messages.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_df_clean |> \n  dplyr::count(text, sort = T) |> \n  print(n = 20)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 24,126 √ó 2\n   text                                 n\n   <chr>                            <int>\n 1 \"<Media omitted>\"                  646\n 2 \"Lol\"                               66\n 3 \"Wow\"                               64\n 4 \"This message was deleted\"          25\n 5 \"\\U0001f923\"                        24\n 6 \"\\U0001fa87\"                        24\n 7 \"?\"                                 22\n 8 \"Yep\"                               21\n 9 \"\\U0001f602\"                        19\n10 \"Ouch\"                              17\n11 \"Racist\"                            17\n12 \"True\"                              14\n13 \"Yeah\"                              14\n14 \"\\U0001f923\\U0001f923\\U0001f923\"    14\n15 \"No\"                                13\n16 \"\\U0001f4af\"                        13\n17 \"\\U0001f937\\U0001f3fc‚Äç‚ôÇÔ∏è\"             13\n18 \"Exactly\"                           12\n19 \"Yes\"                               12\n20 \"lol\"                               12\n# ‚Ñπ 24,106 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\nchat_df_clean <-\n  chat_df_clean |>\n  dplyr::filter(!text %in% c(\"<Media omitted>\", \"This message was deleted\"))\n```\n:::\n\n\nWe also want to remove `\"<<This message was edited>\"` from text\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_df_clean |>\n  dplyr::filter(grepl('<This message was edited>', text))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 299 √ó 3\n   time              name  text                                                 \n   <chr>             <chr> <chr>                                                \n 1 23/8/23, 3:23‚ÄØam  Dave  \"But hendos a hero? <This message was edited>\"       \n 2 23/8/23, 5:56‚ÄØam  Dave  \"And? Brentford snapped it up, small club. You don‚Äôt‚Ä¶\n 3 1/9/23, 10:08‚ÄØpm  Dave  \"As a neutral I was questioning the Saudi link and g‚Ä¶\n 4 11/9/23, 1:02‚ÄØam  James \"I wonder why a more successful club hasn't come in ‚Ä¶\n 5 21/9/23, 7:44‚ÄØpm  Dave  \"Such an ‚Äúalmost‚Äù striker isn‚Äôt he. He‚Äôs got to have‚Ä¶\n 6 25/9/23, 2:36‚ÄØam  Dave  \"Not rice <This message was edited>\"                 \n 7 5/10/23, 4:13‚ÄØam  James \"@61409710717 do you think if you get the spurs game‚Ä¶\n 8 5/10/23, 4:27‚ÄØam  James \"Same CLs as Chelsea who I assume you both think are‚Ä¶\n 9 7/10/23, 10:49‚ÄØam James \"@14244893404 is there an asterisk on everything Var‚Ä¶\n10 8/10/23, 11:33‚ÄØpm James \"Should have beat West Ham too but one point is good‚Ä¶\n# ‚Ñπ 289 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\nchat_df_clean <-\n  chat_df_clean |>\n  dplyr::mutate(text = sub(' <This message was edited>$', '', text))\n\nchat_df_clean |>\n  dplyr::filter(grepl('<This message was edited>', text))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 0 √ó 3\n# ‚Ñπ 3 variables: time <chr>, name <chr>, text <chr>\n```\n\n\n:::\n:::\n\n\n### Split message text into words\n\nWe will split words using a space . This will create a **list column** (since we are using tibbles). We unnest the list column to have the words of a message still associated with the name of the person. And then convert all text to lower case\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_words <-\n  chat_df_clean |>\n  dplyr::mutate(word = strsplit(text, split = ' ')) |>\n  dplyr::select(!text) |>\n  tidyr::unnest(cols = word) |>\n  dplyr::mutate(word = tolower(word))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_words\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 192,250 √ó 3\n   time            name    word   \n   <chr>           <chr>   <chr>  \n 1 5/1/23, 3:55‚ÄØam Gerrard putting\n 2 5/1/23, 3:55‚ÄØam Gerrard the    \n 3 5/1/23, 3:55‚ÄØam Gerrard other  \n 4 5/1/23, 3:55‚ÄØam Gerrard chat   \n 5 5/1/23, 3:55‚ÄØam Gerrard on     \n 6 5/1/23, 3:55‚ÄØam Gerrard mute   \n 7 5/1/23, 3:55‚ÄØam Gerrard and    \n 8 5/1/23, 3:55‚ÄØam Gerrard seeing \n 9 5/1/23, 3:55‚ÄØam Gerrard how    \n10 5/1/23, 3:55‚ÄØam Gerrard it     \n# ‚Ñπ 192,240 more rows\n```\n\n\n:::\n:::\n\n\n#### Cleaning words\n\nRemove stop words, HTTP links, clean punctuation and emojis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_words |>\n  dplyr::count(word, sort = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 19,506 √ó 2\n   word      n\n   <chr> <int>\n 1 the    6522\n 2 a      4187\n 3 to     3560\n 4 and    2876\n 5 in     2541\n 6 i      2388\n 7 you    2220\n 8 of     2166\n 9 is     1945\n10 that   1762\n# ‚Ñπ 19,496 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\n# Include grammatically incorrect stop words from the tidytext list of stop words\n# e.g. don't and dont, i'll and ill\nmy_stop_words <-\n  dplyr::bind_rows(\n    tidytext::stop_words,\n    dplyr::mutate(tidytext::stop_words, word = gsub('[[:punct:]]+', '', word))\n  ) |>\n  dplyr::distinct(word)\n\n# Remove HTTP links, clean punctuation and stop words\nchat_words_clean <-\n  chat_words |>\n  dplyr::filter(!grepl('^@|^http', word)) |>\n  dplyr::mutate(word = gsub('[[:punct:]]+', '', word)) |>\n  dplyr::filter(word != '') |>\n  dplyr::filter(!grepl('^[[:digit:]]+$', word)) |>\n  dplyr::anti_join(my_stop_words, by = 'word')\n```\n:::\n\n\nThere are also emojis in the text. These are annoying to deal with, especially when there are multiple ones together without a space. We will just take the first one if there are many\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_words_clean |> \n  dplyr::filter(emoji::emoji_detect(word))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,810 √ó 3\n   time              name    word                            \n   <chr>             <chr>   <chr>                           \n 1 5/1/23, 8:37‚ÄØam   Shaun   \"\\U0001f605\"                    \n 2 5/1/23, 10:21‚ÄØam  Pero    \"\\U0001f44d\\U0001f44d\\U0001f44d\"\n 3 17/1/23, 9:19‚ÄØpm  Shaun   \"\\U0001f622\"                    \n 4 19/1/23, 10:48‚ÄØpm Chris   \"\\U0001f606\"                    \n 5 20/1/23, 4:00‚ÄØam  Gerrard \"\\U0001f633\"                    \n 6 21/1/23, 12:38‚ÄØpm Jono    \"\\U0001f62e\\U0001f62e\"          \n 7 21/1/23, 2:57‚ÄØpm  Jono    \"\\U0001f605\"                    \n 8 21/1/23, 3:23‚ÄØpm  Jono    \"\\U0001f618\"                    \n 9 21/1/23, 3:28‚ÄØpm  Jono    \"\\U0001f605\"                    \n10 25/1/23, 12:49‚ÄØam Gerrard \"\\U0001f923\"                    \n# ‚Ñπ 1,800 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\nchat_words_clean_emoji <-\n  chat_words_clean |>\n  dplyr::mutate(word = dplyr::case_when(\n    emoji::emoji_detect(word) ~ emoji::emoji_fix(substr(word, 1,1)),\n    .default = word\n  )) \n\nchat_words_clean_emoji |> \n  dplyr::filter(emoji::emoji_detect(word))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,771 √ó 3\n   time              name    word        \n   <chr>             <chr>   <chr>       \n 1 5/1/23, 8:37‚ÄØam   Shaun   \"\\U0001f605\"\n 2 5/1/23, 10:21‚ÄØam  Pero    \"\\U0001f44d\"\n 3 17/1/23, 9:19‚ÄØpm  Shaun   \"\\U0001f622\"\n 4 19/1/23, 10:48‚ÄØpm Chris   \"\\U0001f606\"\n 5 20/1/23, 4:00‚ÄØam  Gerrard \"\\U0001f633\"\n 6 21/1/23, 12:38‚ÄØpm Jono    \"\\U0001f62e\"\n 7 21/1/23, 2:57‚ÄØpm  Jono    \"\\U0001f605\"\n 8 21/1/23, 3:23‚ÄØpm  Jono    \"\\U0001f618\"\n 9 21/1/23, 3:28‚ÄØpm  Jono    \"\\U0001f605\"\n10 25/1/23, 12:49‚ÄØam Gerrard \"\\U0001f923\"\n# ‚Ñπ 1,761 more rows\n```\n\n\n:::\n:::\n\n\nThus our final word counts looks something like this\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_words_clean_emoji |> \n  dplyr::count(word, sort = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 11,013 √ó 2\n   word          n\n   <chr>     <int>\n 1 arsenal     744\n 2 season      673\n 3 liverpool   590\n 4 game        565\n 5 league      518\n 6 team        500\n 7 win         492\n 8 lol         449\n 9 shit        387\n10 fans        374\n# ‚Ñπ 11,003 more rows\n```\n\n\n:::\n:::\n\n\n### Final clean data\n\nWe create two objects\n\n-   chat_text_final: timestamp, name, message text\n-   chat_words_final: timestamp, name, words in text\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_text_final <- chat_df_clean\nchat_words_final <- chat_words_clean_emoji\n\nchat_text_final\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 25,270 √ó 3\n   time            name    text                                                 \n   <chr>           <chr>   <chr>                                                \n 1 5/1/23, 3:55‚ÄØam Gerrard \"Putting the other chat on Mute and seeing how it ta‚Ä¶\n 2 5/1/23, 3:56‚ÄØam Gerrard \"Think we should have a catch over a game sometime, ‚Ä¶\n 3 5/1/23, 3:57‚ÄØam Chris   \"Lol. Silly English.\"                                \n 4 5/1/23, 3:58‚ÄØam Chris   \"Made John disappear. Maybe add him back to this one‚Ä¶\n 5 5/1/23, 3:58‚ÄØam Gerrard \"Added JD\"                                           \n 6 5/1/23, 4:03‚ÄØam Gerrard \"Put some thoughts together on these, or just find a‚Ä¶\n 7 5/1/23, 8:31‚ÄØam Shaun   \"Nobody watches the EPL, it's a second rate league\"  \n 8 5/1/23, 8:32‚ÄØam Gerrard \"Football League One is where it's at\"               \n 9 5/1/23, 8:37‚ÄØam Shaun   \"Can someone stream the game so we can all watch \\U0‚Ä¶\n10 5/1/23, 9:33‚ÄØam Jono    \"I‚Äôm in. Let‚Äôs lock in a date\"                       \n# ‚Ñπ 25,260 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\nchat_words_final\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 75,098 √ó 3\n   time            name    word   \n   <chr>           <chr>   <chr>  \n 1 5/1/23, 3:55‚ÄØam Gerrard putting\n 2 5/1/23, 3:55‚ÄØam Gerrard chat   \n 3 5/1/23, 3:55‚ÄØam Gerrard mute   \n 4 5/1/23, 3:55‚ÄØam Gerrard takes  \n 5 5/1/23, 3:55‚ÄØam Gerrard english\n 6 5/1/23, 3:55‚ÄØam Gerrard notice \n 7 5/1/23, 3:56‚ÄØam Gerrard catch  \n 8 5/1/23, 3:56‚ÄØam Gerrard game   \n 9 5/1/23, 3:57‚ÄØam Chris   lol    \n10 5/1/23, 3:57‚ÄØam Chris   silly  \n# ‚Ñπ 75,088 more rows\n```\n\n\n:::\n:::\n\n\n## Visualisations\n\n### The number of messages by person\n\nBy creating a colour scheme object, we can easily shift between team colours for the plot. Here we will use Arsenal colours, but note the Liverpool once exits.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Arsenal\nbrand_colours <-\n  list(\n    main = \"#EF0107\",\n    sub = \"#023474\",\n    supp = \"#9C824A\",\n    white = \"white\"\n  )\n\n# # Liverpool\n# brand_colours <-\n#   list(\n#     main = \"#C8102E\",\n#     sub = \"#00B2A9\",\n#     supp = \"#F6EB61\",\n#     white = \"white\"\n#   )\n\nchat_text_final |>\n  dplyr::count(name) |>\n  dplyr::arrange(n) |> \n  dplyr::mutate(name = factor(name, levels = name)) |>\n  ggplot(aes(y = name, x = n)) +\n  geom_col(fill = brand_colours$sub) +\n    geom_text(aes(label = n), color = brand_colours$sub, hjust = 0, nudge_x = 10, size = 4,\n            vjust = 0.33) +\n  labs(title = 'Group Chat messages',\n       subtitle = 'since January 2023',\n       y= NULL,\n       x = 'Number of messages sent') +\n  scale_x_continuous(expand = expansion(mult = c(0, 0.1))) +\n  theme(\n    text = element_text(colour = brand_colours$white, size = 16),\n    axis.text = element_text(colour = brand_colours$white),\n    axis.ticks = element_line(colour = scales::alpha(brand_colours$white, 0.5)),\n    axis.ticks.y = element_blank(),\n    axis.text.y = element_text(vjust = 0.35),\n    plot.background = element_rect(fill = brand_colours$main),\n    panel.background = element_rect(fill = brand_colours$main),\n    plot.title.position = 'plot',\n    plot.title = element_text(hjust = 0.5),\n    plot.subtitle = element_text(hjust = 0.5),\n    panel.grid.major.y = element_blank(),\n    panel.grid.major.x = element_line(colour = scales::alpha(brand_colours$white, 0.5)),\n    panel.grid.minor.x = element_blank(),\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\n### Word cloud\n\nWe first need to count the words\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_words_count <-\n  chat_words_final |>\n  dplyr::count(word, sort = T)\n```\n:::\n\n\nAnd create a default word cloud function\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwordcloud_default <- function(data, max.words, title){\n  \n  wordcloud::wordcloud(\n    words = data$word,\n    freq = data$n,\n    scale = c(3, 0.5),    # Set min and max scale\n    max.words = max.words,      # Set top n words\n    random.order = FALSE, # Words in decreasing freq\n    random.color = TRUE,\n    rot.per = 0,      # % of vertical words\n    use.r.layout = FALSE, # Use C++ collision detection\n    colors = unlist(brand_colours[c('main', 'main', 'sub', 'sub', 'supp')]))\n  \n  if (!missing(title)){\n    \n    text(x = 0.5, y = 1, labels = title)\n    \n  }\n  \n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1010)\n\npar(mar = rep(0, 4))\n\nwordcloud_default(chat_words_count, max.words = 100)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-34-1.png){width=480}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nchat_words_count_gerrard <-\n  chat_words_final |>\n  dplyr::filter(name == \"Gerrard\") |>\n  dplyr::count(word, sort = T)\n\nchat_words_count_james <-\n  chat_words_final |>\n  dplyr::filter(name == \"James\") |>\n  dplyr::count(word, sort = T)\n\n# The plot\npar(mfrow = c(1,2), mar = rep(0,4))\n\nwordcloud_default(chat_words_count_gerrard,\n                  max.words = 50,\n                  title = 'Gerrard')\n\nwordcloud_default(chat_words_count_james,\n                  max.words = 50,\n                  title = 'James')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-35-1.png){width=960}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}